# ğŸ“ Connect4-Neuroevo

This project explores **neuroevolution** applied to Connect 4 using the **NEAT algorithm** (NeuroEvolution of Augmenting Topologies). The goal is to evolve neural networks capable of playing Connect 4 against various opponents, from random agents to strategic greedy players.

## ğŸ“‹ Project Overview

The notebook contains a complete pipeline for:

- **Connect 4 Environment**: Custom implementation with optimized win detection
- **Baseline Agents**: Random and greedy (heuristic-based) opponents
- **NEAT Integration**: Neural network evolution with multiple encoding strategies
- **Fitness Functions**: Various approaches including symmetric training, curriculum learning, and co-evolution
- **Analysis Tools**: Fitness plotting, network visualization, and agent comparison matrices

### ğŸ§ª Key Experiments

| Experiment | Description |
|------------|-------------|
| NEAT vs Random | Basic training against random moves |
| NEAT vs Greedy | Training against heuristic opponent |
| Symmetric Training | Balanced first/second player performance |
| Curriculum Learning | Gradual difficulty increase |
| Co-evolution | Training against population peers |
| Encoding Comparison | Simple vs Double vs Pattern-based |

### ğŸ” Main Findings

- NEAT successfully evolves agents for simple scenarios (beating random opponents)
- Feed-forward networks struggle with strategic depth required against greedy agents
- Networks fail to develop defensive/reactive play capabilities
- Larger populations with fewer generations outperform the inverse configuration

## ğŸ“ Repository Structure

â”œâ”€â”€ connect4-neuroevo.ipynb - Main notebook with all experiments

â”œâ”€â”€ neat_config.txt - NEAT configuration parameters

â”œâ”€â”€ best_genome/ - Saved evolved genomes

â”œâ”€â”€ requirements.txt - Python dependencies

â””â”€â”€ README.md - Project overview and instructions

## ğŸš€ Quick Start

### ğŸ“¦ Installation

```bash
pip install -r requirements.txt
```

### â–¶ï¸ Running the Notebook

The notebook uses a control variable `execute_all_cells` at the top:

```python
execute_all_cells = False  # Default
```

#### Two Modes of Operation

| Mode | `execute_all_cells` | What Happens |
|------|---------------------|--------------|
| **Review Mode** | `False` | Loads pre-saved genomes from `best_genome/`, runs demo games and network visualizations. Fast execution (~minutes) |
| **Full Training Mode** | `True` | Re-runs all NEAT evolution experiments from scratch. Very slow execution (~hours) |

**ğŸ’¡ Recommendation**: Keep `execute_all_cells = False` unless you want to reproduce the full evolutionary training. All analysis cells (game demos, network plots, comparison matrices) will still execute using the saved best genomes.

### ğŸ§  Pre-trained Genomes

The `best_genome/` folder contains evolved networks from various experiments:

- `random_agent_encode0.pkl` - Trained vs random agent
- `greedy_agent_encode0.pkl` - Trained vs greedy agent  
- `tune_encode0_*.pkl` - Various fitness function experiments
- `specialist_first.pkl` / `specialist_second.pkl` - Position-specialized agents
- `compare_encode*.pkl` - Different encoding methods

## ğŸ“š Dependencies

- `neat-python` - NEAT implementation
- `numpy` - Numerical operations
- `matplotlib` - Plotting
- `networkx` - Network visualization
- `pandas` / `seaborn` - Comparison matrices

## ğŸ“ Acknowledgments

This project was developed as part of a global and multi-objective optimization course, exploring the capabilities and limitations of neuroevolution for game-playing AI.
